<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Overview 6 Math model review | STAT 764 - Spring 2023</title>
  <meta name="description" content="<p>This is a bookdown project containing the daily journals of STAT 764,
and the activities 1, 2, and 3 at the end of the document.</p>" />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="Overview 6 Math model review | STAT 764 - Spring 2023" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="<p>This is a bookdown project containing the daily journals of STAT 764,
and the activities 1, 2, and 3 at the end of the document.</p>" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Overview 6 Math model review | STAT 764 - Spring 2023" />
  
  <meta name="twitter:description" content="<p>This is a bookdown project containing the daily journals of STAT 764,
and the activities 1, 2, and 3 at the end of the document.</p>" />
  

<meta name="author" content="Valentina M. Pereyra Picabea" />


<meta name="date" content="2024-05-09" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="axis-labels-name-correctly-for-showing-a-histogram-is-a-pdf-is-not-a-count-is-density-in-histfreq-f..html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">STAT 764 - Valentina Pereyra</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="activity-1---morning-walk.html"><a href="activity-1---morning-walk.html"><i class="fa fa-check"></i><b>1</b> Activity 1 - Morning walk</a>
<ul>
<li class="chapter" data-level="1.1" data-path="activity-1---morning-walk.html"><a href="activity-1---morning-walk.html#libraries"><i class="fa fa-check"></i><b>1.1</b> Libraries</a></li>
<li class="chapter" data-level="1.2" data-path="activity-1---morning-walk.html"><a href="activity-1---morning-walk.html#data"><i class="fa fa-check"></i><b>1.2</b> Data</a></li>
<li class="chapter" data-level="1.3" data-path="activity-1---morning-walk.html"><a href="activity-1---morning-walk.html#visualize-map"><i class="fa fa-check"></i><b>1.3</b> Visualize map</a></li>
<li class="chapter" data-level="1.4" data-path="activity-1---morning-walk.html"><a href="activity-1---morning-walk.html#write-kml"><i class="fa fa-check"></i><b>1.4</b> Write kml</a></li>
<li class="chapter" data-level="1.5" data-path="activity-1---morning-walk.html"><a href="activity-1---morning-walk.html#visualize-lat-lon"><i class="fa fa-check"></i><b>1.5</b> Visualize lat lon</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="activity-1---morning-walk.html"><a href="activity-1---morning-walk.html#polynomial"><i class="fa fa-check"></i><b>1.5.1</b> 1. Polynomial</a></li>
<li class="chapter" data-level="1.5.2" data-path="activity-1---morning-walk.html"><a href="activity-1---morning-walk.html#gam---low-rank-gaussian-process"><i class="fa fa-check"></i><b>1.5.2</b> 2. GAM - low rank gaussian process</a></li>
<li class="chapter" data-level="1.5.3" data-path="activity-1---morning-walk.html"><a href="activity-1---morning-walk.html#regression-tree"><i class="fa fa-check"></i><b>1.5.3</b> 3. Regression tree</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="activity-1---morning-walk.html"><a href="activity-1---morning-walk.html#visualize-all"><i class="fa fa-check"></i><b>1.6</b> Visualize all</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="activity-1---morning-walk.html"><a href="activity-1---morning-walk.html#comments"><i class="fa fa-check"></i><b>1.6.1</b> 4. Comments</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="elevation-data-of-experiment-plot-in-north-agronomy-farm.html"><a href="elevation-data-of-experiment-plot-in-north-agronomy-farm.html"><i class="fa fa-check"></i><b>2</b> Elevation data of Experiment plot in North Agronomy Farm</a>
<ul>
<li class="chapter" data-level="2.1" data-path="elevation-data-of-experiment-plot-in-north-agronomy-farm.html"><a href="elevation-data-of-experiment-plot-in-north-agronomy-farm.html#librarires"><i class="fa fa-check"></i><b>2.1</b> Librarires</a></li>
<li class="chapter" data-level="2.2" data-path="elevation-data-of-experiment-plot-in-north-agronomy-farm.html"><a href="elevation-data-of-experiment-plot-in-north-agronomy-farm.html#kansas-boundary"><i class="fa fa-check"></i><b>2.2</b> Kansas boundary</a></li>
<li class="chapter" data-level="2.3" data-path="elevation-data-of-experiment-plot-in-north-agronomy-farm.html"><a href="elevation-data-of-experiment-plot-in-north-agronomy-farm.html#my-data-north-agronomy-farm"><i class="fa fa-check"></i><b>2.3</b> My data: North Agronomy Farm</a></li>
<li class="chapter" data-level="2.4" data-path="elevation-data-of-experiment-plot-in-north-agronomy-farm.html"><a href="elevation-data-of-experiment-plot-in-north-agronomy-farm.html#extract-elevation"><i class="fa fa-check"></i><b>2.4</b> Extract elevation</a></li>
<li class="chapter" data-level="2.5" data-path="elevation-data-of-experiment-plot-in-north-agronomy-farm.html"><a href="elevation-data-of-experiment-plot-in-north-agronomy-farm.html#visualize-boundary-elevation"><i class="fa fa-check"></i><b>2.5</b> Visualize boundary + elevation</a></li>
<li class="chapter" data-level="2.6" data-path="elevation-data-of-experiment-plot-in-north-agronomy-farm.html"><a href="elevation-data-of-experiment-plot-in-north-agronomy-farm.html#models"><i class="fa fa-check"></i><b>2.6</b> Models</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="elevation-data-of-experiment-plot-in-north-agronomy-farm.html"><a href="elevation-data-of-experiment-plot-in-north-agronomy-farm.html#linear-with-iid-errors"><i class="fa fa-check"></i><b>2.6.1</b> 1. Linear with iid errors</a></li>
<li class="chapter" data-level="2.6.2" data-path="elevation-data-of-experiment-plot-in-north-agronomy-farm.html"><a href="elevation-data-of-experiment-plot-in-north-agronomy-farm.html#gam"><i class="fa fa-check"></i><b>2.6.2</b> 2. GAM</a></li>
<li class="chapter" data-level="2.6.3" data-path="elevation-data-of-experiment-plot-in-north-agronomy-farm.html"><a href="elevation-data-of-experiment-plot-in-north-agronomy-farm.html#regression-tree-1"><i class="fa fa-check"></i><b>2.6.3</b> 3. Regression tree</a></li>
<li class="chapter" data-level="2.6.4" data-path="elevation-data-of-experiment-plot-in-north-agronomy-farm.html"><a href="elevation-data-of-experiment-plot-in-north-agronomy-farm.html#support-vector-regression"><i class="fa fa-check"></i><b>2.6.4</b> 4. Support vector regression</a></li>
<li class="chapter" data-level="2.6.5" data-path="elevation-data-of-experiment-plot-in-north-agronomy-farm.html"><a href="elevation-data-of-experiment-plot-in-north-agronomy-farm.html#boosted-regession-tree"><i class="fa fa-check"></i><b>2.6.5</b> 5. Boosted regession tree</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="libraries-1.html"><a href="libraries-1.html"><i class="fa fa-check"></i><b>3</b> Libraries</a>
<ul>
<li class="chapter" data-level="3.1" data-path="libraries-1.html"><a href="libraries-1.html#kansas"><i class="fa fa-check"></i><b>3.1</b> Kansas</a></li>
<li class="chapter" data-level="3.2" data-path="libraries-1.html"><a href="libraries-1.html#land-cover-data"><i class="fa fa-check"></i><b>3.2</b> Land Cover data</a></li>
<li class="chapter" data-level="3.3" data-path="libraries-1.html"><a href="libraries-1.html#raster-w-grassland"><i class="fa fa-check"></i><b>3.3</b> Raster w grassland</a></li>
<li class="chapter" data-level="3.4" data-path="libraries-1.html"><a href="libraries-1.html#compare-models"><i class="fa fa-check"></i><b>3.4</b> Compare models</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="libraries-1.html"><a href="libraries-1.html#concurvity"><i class="fa fa-check"></i><b>3.4.1</b> Concurvity</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="libraries-1.html"><a href="libraries-1.html#semivariogram-for-corr-resids"><i class="fa fa-check"></i><b>3.5</b> Semivariogram for corr resids</a></li>
<li class="chapter" data-level="3.6" data-path="libraries-1.html"><a href="libraries-1.html#predictions-in-space"><i class="fa fa-check"></i><b>3.6</b> Predictions in space</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="libraries-1.html"><a href="libraries-1.html#summary"><i class="fa fa-check"></i><b>3.6.1</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="daily-journals.html"><a href="daily-journals.html"><i class="fa fa-check"></i><b>4</b> Daily journals</a>
<ul>
<li class="chapter" data-level="4.1" data-path="daily-journals.html"><a href="daily-journals.html#january-18"><i class="fa fa-check"></i><b>4.1</b> January 18</a></li>
<li class="chapter" data-level="4.2" data-path="daily-journals.html"><a href="daily-journals.html#january-25"><i class="fa fa-check"></i><b>4.2</b> January 25</a></li>
<li class="chapter" data-level="4.3" data-path="daily-journals.html"><a href="daily-journals.html#january-30"><i class="fa fa-check"></i><b>4.3</b> January 30</a></li>
<li class="chapter" data-level="4.4" data-path="daily-journals.html"><a href="daily-journals.html#february-1"><i class="fa fa-check"></i><b>4.4</b> February 1</a></li>
<li class="chapter" data-level="4.5" data-path="daily-journals.html"><a href="daily-journals.html#february-6"><i class="fa fa-check"></i><b>4.5</b> February 6</a></li>
</ul></li>
<li><a href="axis-labels-name-correctly-for-showing-a-histogram-is-a-pdf-is-not-a-count-is-density-in-histfreq-f..html#axis-labels-name-correctly-for-showing-a-histogram-is-a-pdf-is-not-a-count-is-density-in-histfreq-f." id="toc-axis-labels-name-correctly-for-showing-a-histogram-is-a-pdf-is-not-a-count-is-density-in-histfreq-f."><span class="toc-section-number">5</span> Axis labels: name correctly for showing a histogram: is a pdf, is not a count, is density, in hist(freq = F).<br />
</a></li>
<li class="chapter" data-level="6" data-path="math-model-review.html"><a href="math-model-review.html"><i class="fa fa-check"></i><b>6</b> Math model review</a>
<ul>
<li class="chapter" data-level="6.1" data-path="math-model-review.html"><a href="math-model-review.html#february-8"><i class="fa fa-check"></i><b>6.1</b> February 8</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="math-model-review.html"><a href="math-model-review.html#cleaned"><i class="fa fa-check"></i><b>6.1.1</b> Cleaned</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="math-model-review.html"><a href="math-model-review.html#februrart-13"><i class="fa fa-check"></i><b>6.2</b> Februrart 13</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="math-model-review.html"><a href="math-model-review.html#cleaned-1"><i class="fa fa-check"></i><b>6.2.1</b> Cleaned</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="math-model-review.html"><a href="math-model-review.html#february-15"><i class="fa fa-check"></i><b>6.3</b> February 15</a></li>
<li class="chapter" data-level="6.4" data-path="math-model-review.html"><a href="math-model-review.html#february-20"><i class="fa fa-check"></i><b>6.4</b> February 20</a></li>
<li class="chapter" data-level="6.5" data-path="math-model-review.html"><a href="math-model-review.html#february-22"><i class="fa fa-check"></i><b>6.5</b> February 22</a></li>
<li class="chapter" data-level="6.6" data-path="math-model-review.html"><a href="math-model-review.html#february-27"><i class="fa fa-check"></i><b>6.6</b> February 27</a></li>
<li class="chapter" data-level="6.7" data-path="math-model-review.html"><a href="math-model-review.html#february-29"><i class="fa fa-check"></i><b>6.7</b> February 29</a></li>
<li class="chapter" data-level="6.8" data-path="math-model-review.html"><a href="math-model-review.html#march-7"><i class="fa fa-check"></i><b>6.8</b> March 7</a></li>
<li class="chapter" data-level="6.9" data-path="math-model-review.html"><a href="math-model-review.html#march-19"><i class="fa fa-check"></i><b>6.9</b> March 19</a></li>
<li class="chapter" data-level="6.10" data-path="math-model-review.html"><a href="math-model-review.html#march-21"><i class="fa fa-check"></i><b>6.10</b> March 21</a></li>
<li class="chapter" data-level="6.11" data-path="math-model-review.html"><a href="math-model-review.html#march-26"><i class="fa fa-check"></i><b>6.11</b> March 26</a></li>
<li class="chapter" data-level="6.12" data-path="math-model-review.html"><a href="math-model-review.html#march-28"><i class="fa fa-check"></i><b>6.12</b> March 28</a></li>
<li class="chapter" data-level="6.13" data-path="math-model-review.html"><a href="math-model-review.html#april-2"><i class="fa fa-check"></i><b>6.13</b> April 2</a></li>
<li class="chapter" data-level="6.14" data-path="math-model-review.html"><a href="math-model-review.html#april-4"><i class="fa fa-check"></i><b>6.14</b> April 4</a></li>
<li class="chapter" data-level="6.15" data-path="math-model-review.html"><a href="math-model-review.html#april-11"><i class="fa fa-check"></i><b>6.15</b> April 11</a></li>
<li class="chapter" data-level="6.16" data-path="math-model-review.html"><a href="math-model-review.html#april-16"><i class="fa fa-check"></i><b>6.16</b> April 16</a></li>
<li class="chapter" data-level="6.17" data-path="math-model-review.html"><a href="math-model-review.html#april-18"><i class="fa fa-check"></i><b>6.17</b> April 18</a></li>
<li class="chapter" data-level="6.18" data-path="math-model-review.html"><a href="math-model-review.html#april-23"><i class="fa fa-check"></i><b>6.18</b> April 23</a></li>
<li class="chapter" data-level="6.19" data-path="math-model-review.html"><a href="math-model-review.html#april-30"><i class="fa fa-check"></i><b>6.19</b> April 30</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">STAT 764 - Spring 2023</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="math-model-review" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">Overview 6</span> Math model review<a href="math-model-review.html#math-model-review" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Differential equations: dynamical systems: they have time in them. Time as continuous 
Difference equations: discrete time version of differential equations. Time as discrete<br />
*When would you use one on another? ask in journal.<br />
<br />
Partial differential equations: use space and time! we use a difference equation anyway</p>
<div id="february-8" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> February 8<a href="math-model-review.html#february-8" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Today we learned that the main difference between spatio-temporal data and the rest is that location and date (most of the times) should be measured. Spatio-temporal data is useful not only to predict location, there’s data that needs location and time to be useful such as temperature and rainfall where we might use location and time as the predictor variables. So we are not interested in predicting location here but to use it as a explanatory variable.<br />
<br />
We also differentiated between a model and an equation, a model is an equation that corresponds to something more or less real.
We recall that difference and differential equations use time as discrete and continuous, respectively.
Differential are difficult to understand and usually we need proficient knowledge of mathematics to work with them. Difference equations are more easy to use and to come up with an equation.<br />
<br />
I also learned about agent-based models, they are simulation models that tend to be used without having data and resembles a video game. For example, they can study how to evacuate a building if it gets on fire where we can make assumptions such as: 90% of the people will stay calm, 10% will freak out and complicate the exit doors.<br />
<br />
Whooping crane example: when the population will be larger than 1000 individuals. They got sued because the way they were counting whooping cranes?? what the heck? they had to start estimating them with prediction intervals. Models that could work for this data?<br />
<br />
Hierarchical models: big deal, Empirical hierarchical model or Bayesian hierarchical model framework:<br />
* Data model <em>: PDF, data we observed z (model for the data I have) conditioned on y (data we wish we had, because all data are collected with error) and some parameters.<br />
</em> Process model <em>: statistical model for the data we wish we had. Up to here we have a classical empirical hierarchical model.<br />
</em> Parameters model: * specific to Bayesian almost always. Also called prior.<br />
<br />
Bayes theorem: obtain posterior distribution of something we care about given the data. Probabilistic predictions and forecasts.<br />
<br />
It would be really interesting if you could show how you approached the giant fish model with a hierarchical Bayesian model.</p>
<p>Example:
Data model: z is a column vector with each observation of whooping cranes. We need to choose a distribution for z and it will be conditioned on y and some parameters. What is y? is a column vector also, it is the true number of whooping cranes. But we don’t know the true number.</p>
<div id="cleaned" class="section level3 hasAnchor" number="6.1.1">
<h3><span class="header-section-number">6.1.1</span> Cleaned<a href="math-model-review.html#cleaned" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Today, we learned that spatio-temporal data differentiates from the rest because location and date (most of the time) should be measured. Spatio-temporal data is useful not only to predict location; some data needs location and time to be useful, such as temperature and rainfall, where we might use them as the predictor variables. So, we are not interested in predicting location here but in using it as an explanatory variable.<br />
<br />
We recall that difference and differential equations use time as discrete and continuous, respectively, and the latter are difficult to understand. Usually, we need proficient knowledge of mathematics to work with them, while difference equations are easier to use and come up with an equation.<br />
<br />
We touched base on agent-based models, which are simulation models that tend to be used without initial data and resemble a video game. For example, they can study how to evacuate a building if it gets on fire, where we can make assumptions such as 90% of the people will stay calm, and 10% will freak out and complicate the exit doors.<br />
<br />
We introduce hierarchical models as the “big deal” and describe empirical and Bayesian hierarchical model framework:<br />
* Data model: PDF of the data we observed (z, model for the data I have) conditioned on y (data we wish we had because all data collected has an error) and some parameters.<br />
* Process model: model for the data we wish we had. Up to here, we have a classical empirical hierarchical model.<br />
* Parameter model: specific to Bayesian almost always. Also called prior distribution.<br />
</p>
<p>It would be really interesting if you showed how you approached the giant fish model with a hierarchical Bayesian model approach. I’m curious to learn how you could account for &gt;100 species of fish and come up with useful results to control the water flow. And maybe beyond statistics, but how did they weigh the decision on this because any water flow would be ok for some but not all species.</p>
</div>
</div>
<div id="februrart-13" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> Februrart 13<a href="math-model-review.html#februrart-13" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Chapter 5 mechanistic space models - we will talk today. But start reading chapter 4 for next week.<br />
Whooping crane model: first remind yourself about your goals: predict and forecast the true population size, and statistical inference on the day when population will be &gt; 1000 individuals.<br />
*Space stats falls in between forecast-prediction and inference.<br />
Remember: open the computer and R is not the first thing to do, like stretching before running, here you may need to take a paper and draft and draft what you want to do.<br />
<br />
Hierarchical models: zero time searching in the internet, after having your goals write down your data + process + parameter (if bayesian) models.<br />
We like to use bayesian because once we specify our models (picking distributions + assumptions - model specification), we apply bayes theorem and all will go smooth (model fitting). None thought needed for obtaining a posterior distribution, the software will do it for us. Brain consuming: model specification!<br />
<br />
1. <strong>Data model:</strong><br />
The model for the data that was generated or collected. <span class="math inline">\(z\)</span> is the count through time in the form of a vector.<br />
<span class="math inline">\([z|y, \theta_D]\)</span>, <span class="math inline">\(y\)</span>= true population size of whooping cranes, <span class="math inline">\(|\)</span> = givent that.<br />
<span class="math inline">\(\theta_D\)</span>= represent the parameters in our data model, in this case would be the probability of a whooping crane being seeing, <span class="math inline">\([]\)</span> = PDF.<br />
<br />
Support of <span class="math inline">\(z\)</span> and <span class="math inline">\(y\)</span>: values that the distribution could generate, if I flip a coin the support is cons or tails, if I through a dice the support is 1, 2, 3, 4, 5, 6.<br />
<br />
<span class="math inline">\(0&lt; y &lt; inf\)</span>= integers, not half bird. Lower bound: zero, no negatives. Upper bound: more negotiable, we can call it infinite.<br />
<span class="math inline">\(0 &lt; z &lt; y\)</span>= support is something less than <span class="math inline">\(y\)</span>.<br />
We can choose binomial distribution distribution of <span class="math inline">\(z\)</span>, in rbinom() (take draws from a distribution).<br />
For examples rbinom(n=1,size=1000,prob=0.5), true population = 1000, probability that the guy will count all of them prob = 0.5. Size = 1000 is the number of trials but we are calling it the TRUE POPULATION OF WHOOPING CRANES!, the draws will be ~500. If the guy is cocky he could say prob=1.0 and result would be 1000.<br />
<br />
Data model:
<span class="math inline">\([z|y,p]=Bin(y,p)\)</span> y num of trials, p prob of success.<br />
<br />
2. <strong>Process model:</strong> model for data I wish I had.<br />
<br />
Assuming our data is perfect what model we would use. <span class="math inline">\([y|\theta_P]\)</span><br />
True number of whooping cranes &gt; 0, with no known upper bound, this leads to another distribution, Poisson!<br />
In R rpois(n=1, lambda=10), n = number of draws, lambda is the parameter of a poisson distribution, is the expected value and the variance. The mean of many draws will be ~10.<br />
<br />
<span class="math inline">\([y|]=Pois()\)</span>, specify a model that controls expected value of Pois() could be a constant or a linear model. We restrict the support to &gt;0 by elevating e to the equation.<br />
So, <span class="math inline">\(\lambda\)</span> is the expected value of Pois(). Pois() is the “more appropriate” for count data when we dont know the upper bound.<br />
<br />
3. <strong>Parameter model:</strong><br />
<span class="math inline">\(\lambda_o ~ dunif(2, 50)\)</span><br />
<span class="math inline">\(\gamma ~ unif(0,0.1)\)</span>, <span class="math inline">\(\gamma\)</span>=growth rate greater than 0 and less than 10%.</p>
<div id="cleaned-1" class="section level3 hasAnchor" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> Cleaned<a href="math-model-review.html#cleaned-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Yesterday in class, we reviewed the steps to build a model, starting by clearly stating our goals. For the whooping crane example, our goals are to predict and forecast the true population size and to make inference on the day when the population size will be greater than 1000 individuals. This is a “great” example of a space-time statistical model, usually, they fall between forecast-prediction and inference. Stating our goals first means we shouldn’t open our programming software before knowing our objectives and what we need to do.<br />
<br />
Second step, especially for a hierarchical model approach (still without opening R).<br />
Write down data + process + parameter (if Bayesian) models, this is where our knowledge in mathematics and stats takes action.<br />
<br />
<strong>Data model:</strong> The model for the data that was generated or collected. <span class="math inline">\(z\)</span> is the count through time in the form of a vector.<br />
<span class="math inline">\([z|y, \theta_D]\)</span>, <span class="math inline">\(y\)</span>= true population size of whooping cranes. <span class="math inline">\(\theta_D\)</span>= represent the parameters in our data model, in this case would be the probability of a whooping crane being seen.<br />
Support of <span class="math inline">\(z\)</span> and <span class="math inline">\(y\)</span>: important for picking a distribution, they are the values the distribution could generate.<br />
<span class="math inline">\(0&lt; y &lt; inf\)</span>, integers.<br />
<span class="math inline">\(0 &lt; z &lt; y\)</span>= support is something less than <span class="math inline">\(y\)</span>.<br />
We can choose binomial distribution distribution for <span class="math inline">\(z\)</span>, rbinom() (take draws from a distribution).<br />
For example, rbinom(n=1,size=1000,prob=0.5), true population = 1000, probability that the guy will count all of them prob = 0.5. Size = 1000 is the number of trials but we call it the TRUE POPULATION OF WHOOPING CRANES!, the mean of the draws will be ~500.<br />
<strong>Process model:</strong> model for data I wish I had. Assuming our data is perfect, what model would we use. <span class="math inline">\([y|\theta_P]\)</span><br />
The true number of whooping cranes &gt; 0, with no known upper bound, this leads to another distribution, Poisson!<br />
In R rpois(n=1, lambda=10), n = number of draws, lambda is the parameter of a poisson distribution, is the expected value and the variance. The mean of many draws will be ~10.<br />
<br />
<strong>Parameter model:</strong><br />
<span class="math inline">\(\lambda_o \sim unif(2, 50)\)</span><br />
<span class="math inline">\(\gamma \sim unif(0,0.1)\)</span>, <span class="math inline">\(\gamma\)</span>=growth rate greater than 0 and less than 10%.<br />
<br />
I struggle to understand some of the math concepts related to difference and differential equations. Even though I won’t be able to understand the majority of these concepts in this class (because we should know from previous classes), I struggle to understand how students without this knowledge could arrive to a space-time model suitable for our needs. I would like to go through an example like the giant fish where we can probably build up what we saw with the whooping crane example into something more complex.</p>
</div>
</div>
<div id="february-15" class="section level2 hasAnchor" number="6.3">
<h2><span class="header-section-number">6.3</span> February 15<a href="math-model-review.html#february-15" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Today in class we reviewed Bayesian hierarchical modelling approach, with the example of the whooping cranes:<br />
<br />
Review from data model: <span class="math inline">\([ \underline{z} |\underline{y},p]=\beta_{in}(\underline{y},p)\)</span> +<br />
Process model: <span class="math inline">\([y_t|\sigma, \lambda_t] = Pos(\lambda_t)\)</span>, <span class="math inline">\(\lambda_t=\lambda_oe^{\gamma(t-t_0)}\)</span> +<br />
Parameter model: <span class="math inline">\([\gamma]=unif(0,0.1)\)</span>, <span class="math inline">\([\lambda_o]=dunif(2,50)\)</span>, <span class="math inline">\([\gamma]\)</span> needs to be discrete, it has to be an integer, <span class="math inline">\([p]=unif(0,1)\)</span><br />
<br />
Once we reviewed the model and our assumptions in the board, we proceed to show each of these steps in R software.<br />
1. We built functions for calculating lambda and the discrete uniform distribution,<br />
2. Defined number of simulated data sets to make (K.tries),<br />
3. Defined known random variables and parameters (t0, t, and n),<br />
4. Created matrix to save unknown parameters (gamma, lambda, p),<br />
5. Created matrix to save true unknown number of whooping cranes,<br />
6. Created matrix to save number of observed (counted) whooping cranes,<br />
7. For loop from 1 to K.tries: sample from parameter model for process model (gamma.try, lambda0.try, and p), we calculated lambda (estimated growth rate), we sampled from the process model (function for lambda.try), and finally sampled from our data model (z.try).<br />
<br />
Then we plotted three simulations from K.tries and observed that they can be quite different between them.<br />
<br />
After this we returned to the bookdown, a) we set an allowable difference between the observed and simulated data of 1000 whooping cranes, b) recorded the difference between the z (prior predictive distribution) and observed data, and c) calculated the acceptance rate (proportion where the difference between observed and simulated &lt;1000). And finally plotted the approximate posterior distribution of parameters gamma, lambda0, and p after filtering for the acceptance rate.<br />
<br />
I’m struggling to understand the difference between the approach we did today in class and MCMC, mainly how we would approach MCMC with this same example.<br />
I want to say that this was the best class ever!! I really liked how you went from crafting the data, process, and parameter model, translate them. into R software, applied the algorithm and plotted the results. I would really like to keep doing examples where we literally code data+process+parameter models and see a result. This made me understand a lot about many concepts we covered in STAT 768. I think this is a really good way to learn for non-stat majors.</p>
</div>
<div id="february-20" class="section level2 hasAnchor" number="6.4">
<h2><span class="header-section-number">6.4</span> February 20<a href="math-model-review.html#february-20" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Today in class, we introduced activity 2, where we will have to choose an area around campus and record our elevation at many locations with our cellphones. Then, obtain a .gpx file, load it into R, and plot it, similar to the example we saw in class.<br />
We discussed the use of packages in general and the sf package from R in particular, and how difficult it is, sometimes, to achieve tasks due to maintenance by authors (or lack thereof). Working with geospatial data in R is a challenge, many packages that work just sometimes, so it would be safer to create our own custom functions.<br />
<br />
Then we reviewed the concepts already covered in class, from Matrix algebra and distribution theory to the hierarchical model framework, a powerful statistical approach because it acknowledges measurement error in our data.<br />
<br />
As we saw in previous classes, we built our statistical model by choosing an appropriate PDF or PMF for the data, process, and parameter models, we then choose mathematical models for the parameters or moments from step 1, and choose an algorithm to fit the model and make statistical inference.<br />
<br />
THE most important skills: have important goals for your analysis, the first and most important step. Usually contains both prediction/forecasting and statistical inference.<br />
Very important but not the most: write your statistical model.<br />
Not very important: programming software to fit model.<br />
<br />
We introduced an example of extreme precipitation in KS to predict and quantify the uncertainty of rainfall events. First, we defined the goals and then got the data.<br />
<br />
I struggle to understand how we can manage missing data in this case of weather data. And what can we do when we have many consecutive days with missing data from rainfall or temperature. Recently, I downloaded weather data from NOAA manually (without the rnoaa package), and it had so many missing dates that I gave up on NOAA and used MESONET.</p>
</div>
<div id="february-22" class="section level2 hasAnchor" number="6.5">
<h2><span class="header-section-number">6.5</span> February 22<a href="math-model-review.html#february-22" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Today in class, we introduced some Geographic Information Systems (GIS) concepts and covered the four main types of data we will use (shapefiles, rasters, and points). Shapefiles represent continuous spatial objects and boundaries in a vector format (i.e., rivers, cities, fields). Raster files are rectangular matrices or grids of pixels visualized as georeferenced images. We reviewed some examples of raster databases like PRISM (weather data) and CROPSCAPE (cropland data layer). Raster images are often model-based predictions because observations are finite in space, and interpolation to all the area is needed to have a “complete” data set in space. Raster can be big (many MG or GB) files and are difficult to work with in R. Points files are coordinates + a coordinate system. Using R as a tool for GIS can be frustrating because new packages are released often, they work for some time, and then they stop maintaining them.<br />
<br />
After covering these topics, we introduced the Gaussian process as a probability distribution over functions, if those functions are observed, then each vector of values follows a multivariate normal distribution. The normal distribution is (almost) always trash, the multivariate normal distribution is really useful.<br />
<br />
I struggle to understand the Gaussian process, but I guess we will cover those in future classes, and I think it would be great to see an example like the one we saw last week with Gaussian process. I also got curious about Carlos’ question on the error propagation of (if I remember well) raster files.</p>
</div>
<div id="february-27" class="section level2 hasAnchor" number="6.6">
<h2><span class="header-section-number">6.6</span> February 27<a href="math-model-review.html#february-27" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Yesterday in class we covered concepts related to the Gaussian process (probability distribution that generates a function), mainly related to the multivariate normal distribution (MVN).<br />
<span class="math inline">\(\boldsymbol{\eta} \sim N(0, \sigma^2R)\)</span>, MVN. Variance covariance matrix part of a MVN.<br />
<strong>Correlation matrix (R):</strong> describes correlation between each element of random variable <span class="math inline">\(\boldsymbol{\eta}\)</span>.<br />
<strong>Correlation function:</strong> function describing the correlation.<br />
<strong>Compound symmetry matrix:</strong> all pairs of measurements have the same correlation and all diagonal elements have a value of 1.<br />
<strong>Autoregressive of order 1 - AR(1):</strong> commonly used for modelling time and spatial data where observations are equidistant in time. The structure assumes that observations closer in time are more correlated than those farther apart. <span class="math inline">\(\phi\)</span> represents the autoregressive parameter, which controls the strength of correlation decay over time in the AR(1).<br />
<br />
We saw an example simulating a MVN with mvrnnorm() in R, where we have to specify a variance covariance matrix (I-identity matrix) and a variance <span class="math inline">\(\sigma\)</span>, and then checked the autocorrelation with acf().<br />
<br />
We then introduced the <strong>Linear models for correlated errors</strong> (Krigging).<br />
<span class="math inline">\(y_i=\beta_0+\beta_1X_i+\eta_i+\epsilon_i\)</span><br />
<span class="math inline">\(\epsilon_i \sim N(0,\sigma^2)\)</span> describes uncorrelated components.<br />
<span class="math inline">\(\eta \sim MVN(0, ?)\)</span> describes correlated components, its a random parameter.<br />
parameters: <span class="math inline">\(2\eta+2\)</span> for beta_0 and beta_1.<br />
<br />
Example, bioluminescence:<br />
To start: intercept only model <span class="math inline">\(y_i=\beta_0+\epsilon_i\)</span>, <span class="math inline">\(\epsilon \sim N(0, \sigma^2)\)</span><br />
Do I model it on the expected value, or do I model it on the variance - spatial stats is all about modelling on the 2nd moment (in the variance). So we “fix” the problem by adding a spatial random effect:<br />
<span class="math inline">\(y_i=\beta_0+\epsilon_i+\eta_i\)</span>, <span class="math inline">\(\epsilon \sim N(0, \sigma^2)\)</span>, <span class="math inline">\(\eta=(\eta_1, \eta_2...\eta_n) \sim MVN(0, \sigma^2R)\)</span><br />
<br />
I struggle to understand the different implications of modelling for the expected value vs on the variance, I would like to know more about this.<br />
<br />
I’m analyzing data of my own research, and I want to “group” the data by similar environments (north, central, and south of the U.S.), in my case using kmeans (something I would like to discuss in our meeting). Once I have those clusters the simplest approach would be to treat those independently and run a model for each (i.e. to see what covariates relates more with yield, protein, oil - my response variables). My question is, I loose a big part of the story by treating those clusters independently and I would like to know how to include the cluster as an effect (like a random effect?).</p>
<p>Generalized least squares (GLS in R): you have options ml, ls more than one algorithm option so is not always least squares!! shit name.<br />
We define the correlation function as a function of the distance which is the depth.<br />
<span class="math inline">\(E(y)=\beta_0+\eta\)</span><br />
We did an intercept only model with gls, as homework we can try adding a slope parameter, that was really an intercept only model that fitted the points son well?</p>
</div>
<div id="february-29" class="section level2 hasAnchor" number="6.7">
<h2><span class="header-section-number">6.7</span> February 29<a href="math-model-review.html#february-29" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Yesterday in class, we covered an example of linear models for correlated errors using the bioluminescent data.<br />
First we run an intercept-only model <span class="math inline">\(y_i=\beta_0+\epsilon_i\)</span>, <span class="math inline">\(\epsilon_i \sim N(0, \sigma^2_i)\)</span>.<br />
We then run an intercept only linear model with spatial random effect:
Linear model for correlated errors:<br />
<span class="math inline">\(y_i=\beta_0+\eta_i+\epsilon_i\)</span>, <span class="math inline">\(\epsilon \sim N(0,\sigma^2)\)</span>, spatial model by adding space term effect.<br />
At each depth, <span class="math inline">\(\eta\)</span> is the spatial effect for every observation.<br />
We add an assumption there: <span class="math inline">\(\eta=(\eta_1, \eta_2,...,\eta_n) \sim MVN(0, \sigma_2C)\)</span>.<br />
<br />
We also wrote a hierarchical model for the rainfall <a href="data:\" class="uri">data:\</a>
Data model:<span class="math inline">\([z|y]=N(y, \sigma^2_z)\)</span> z=measured rainfall, given some parameters |, y = true rainfall. It incorporates error in the <span class="math inline">\(\sigma^2_z\)</span>, is the variance from <span class="math inline">\(\epsilon_i\)</span>.<br />
As a regression model the data model would be: <span class="math inline">\(z=y+\epsilon\)</span>, <span class="math inline">\(\epsilon \sim N(0, \sigma^2)\)</span>.<br />
Process model:<span class="math inline">\([y|\beta_0,\phi,\sigma^2]=MVN(\beta_0,\sigma^2C)\)</span> model for the data I wish I had.<br />
If it were Bayesian, we would put a model for the parameters, but we won’t go that way. It’s an empirical hierarchical model, often fitted with maximum likelihood (vs Bayesian, which is fitted with Bayes’ theorem).<br />
<br />
And then we run a live example in R going through an intercept only model, a second-order polynomial incorporating the spatial effect, and lastly the hierarchical empirical model. The hierarchical model was the most accurate to predict precipitation. This example was really helpful to understand the differences and advantages between them.<br />
I struggle to understand how the gls function works in R, and what each argument means comparing to the statistical models that we write.</p>
</div>
<div id="march-7" class="section level2 hasAnchor" number="6.8">
<h2><span class="header-section-number">6.8</span> March 7<a href="math-model-review.html#march-7" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Yesterday in class we reviewed part of the code from the Dickens Hall parking lot example. We saw the example of low rank gaussian model using mgcv, the rpart example with vertical elevation spots like a staircase. We saw the example of the boosted regression tree that try to “smooth” the cliffs compred to a single regression tree. Boosted regression trees are additive regression models in which individual terms are simple trees, so it fit many models and combine them for prediction.<br />
<br />
Following, we continued an in-class work day for working in our individual projects. I discussed about the analysis with other students who gave me good feedback and helped me to move forward with it.<br />
</p>
</div>
<div id="march-19" class="section level2 hasAnchor" number="6.9">
<h2><span class="header-section-number">6.9</span> March 19<a href="math-model-review.html#march-19" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Today, we reviewed concepts covered in class such as matrix algebra and distribution theory. They are not really from spatial stats, but they are concepts we should know from before. Also, we talked about the philosophy of statistical modeling in terms of what we think a statistical model is (i.e., a simplification of the reality with error.)<br />
The whooping crane data was an example of hierarchical modeling.<br />
The linear model for correlated errors is an empirical hierarchical model (non-Bayesian) and is the usual spatial stats model.<br />
The model-building process: again, the most important skill is writing out the goals of your analysis, which usually contain prediction or forecasting and statistical inference. 2nd important skill is writing down your statistical model, 3rd important skill is knowing a statistical programming language to fit the model.<br />
<br />
Finished up with Kansas rainfall <a href="example:\" class="uri">example:\</a>
The non-hierarchical linear model with identical errors has limitations because it takes on negative values and is far from the maximum value of pp, and it doesn’t do a good job of copying the variability in space (Wiggliness).<br />
The hierarchical linear model with two error terms does a way better job in copying the spatial variability but is still far in the maximum values of pp, and is complex to compute in R.<br />
The third model is a hierarchical linear model with two error terms using low-rank approximation (resembles model kriging) which improves the predictions compared to the previous one.<br />
Lastly, the GAM assuming a Tweedie distribution with a spatial random effect (Gaussian process) best predicted rainfall in Kansas because it captured the lowest and highest precipitations observed.<br />
<br />
In the last model, I struggle to understand why we are calling the spatial effect a random effect, and overall I have a hard time following these models because some fundamental previous knowledge I lack.</p>
</div>
<div id="march-21" class="section level2 hasAnchor" number="6.10">
<h2><span class="header-section-number">6.10</span> March 21<a href="math-model-review.html#march-21" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>During this class I worked on Activity 2. I uploaded the data I recorded in the North Agronomy Farm at K-State, I choose a plot that we use every year (since I’m around) for experimental trials. I chose this site with the objective of checking if there is any major difference between the lowest and highest elevation that could affect the allocation of treatments and blocking. I think for this data, the linear model with iid errors (polynomial), the gam model, support vector regression and the boosted regression tree worked good. They could capture the ~1m difference between the lowest and highest point and the observed predictions made sense compared to what we observed.<br />
<br />
I would like to know which of the models to choose, since all those seems to be working more or less fine, and we shall cover that in the next task of activity 2.</p>
</div>
<div id="march-26" class="section level2 hasAnchor" number="6.11">
<h2><span class="header-section-number">6.11</span> March 26<a href="math-model-review.html#march-26" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Today in class we kept exploring the Dickens Hall Parking Lot example. We model the data using GAM and Boosted Regression Tree. Once we checked the predictions using the training data, we brought a new data set for model checking and comparison. We used this new data to make predictions with the model fitted before, and compared the predicted vs the observed values. Following, we quantified the predictive accuracy using scoring rules. We used the logarithmic scoring rule (proper in all situations, the higher the better), the mean square error (appropriate only with normally distributed data), and the mean absolute error (better for interpretation since it will have the units of the response). Lastly, we determined (only for the linear models run with lm), what percentage (%) of the new observations falls within the 95% prediction interval. This is called calibration, if the model is calibrated it should cover 95% of the new observations. In our case using the polynomial model the data covered within the prediction was 83%.<br />
<br />
You did mentioned that, as a good practice, we should always have an extra data set for model checking (best case scenario), or otherwise split part of our data for model fitting and model checking. I always have the doubt if this is something I would like to do with my own data. For example in the analysis I’m doing now, I like to say that I want to do inference on what happened to the observed data (model fitting I guess), since I don’t think the data would be sufficient or complex enough to predict new observations. But anyways, I understand this is kind of a halfway approach.</p>
</div>
<div id="march-28" class="section level2 hasAnchor" number="6.12">
<h2><span class="header-section-number">6.12</span> March 28<a href="math-model-review.html#march-28" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Today in class we worked on our final projects, specifically advancing the analysis of my prelims. Next week I will start working more specifically in the class project trying to adapt my current analysis to include a spatial component.<br />
<br />
I have no questions or doubts at the moment.</p>
</div>
<div id="april-2" class="section level2 hasAnchor" number="6.13">
<h2><span class="header-section-number">6.13</span> April 2<a href="math-model-review.html#april-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Today in class we had a quick look at the tutorial (Appendix S1) of a manuscript doing spatio-temporal analysis on the distribution of aphids in Kansas (R. padi, S. avenae, and S. graminum), which are vectors of Barley Yellow Dwarf Virus (BYDV). Following an explanation of the data, we explored similar models with a lived example. The abundance of the Bird Cherry aphid is a type of count data, where we have several points across kansas with the location (latitude and longitude), how many aphids were counted, and the proportion of them that were infected with the disease. We plotted the land cover of Kansas, and specifically, we selected lands covered by herbaceous (areas dominated by herbaceous vegetation or gramanoids, i.e., grasslands). We created a variable characterizing the % of grassland within a 5 km radius around the sample location of aphids. We used this variable as our predictor in three different spatio-temporal models to describe the abundance of the aphid. We obtained the predicted abundance of the aphid at 0% and 100% of grassland coverage.<br />
<br />
I guess I am not really sure how I will include the space component in my data, I dont see it feasible to include it for predicting, say, protein concentration in soybeans.</p>
</div>
<div id="april-4" class="section level2 hasAnchor" number="6.14">
<h2><span class="header-section-number">6.14</span> April 4<a href="math-model-review.html#april-4" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Today in class we worked on our Final Project, specifically advancing the analysis of my prelims. This week I will start working more specifically in the class project trying to adapt my current analysis to include a spatial component.<br />
<br />
I have no questions or doubts at the moment.</p>
</div>
<div id="april-11" class="section level2 hasAnchor" number="6.15">
<h2><span class="header-section-number">6.15</span> April 11<a href="math-model-review.html#april-11" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Last April 11, we did an in-class work day advancing Activity 3. The data we used consists on abundance data of the English grain aphid on 341 points collected across the state of Kansas during 2014 and 2015. The English grain aphid is a vector of the barley yellow dwarf virus (BYDV), a member of the Luteoviruses, which is a group of five closely related virus strains. BYDV can be transmitted by more than 20 aphid species, being the most important the bird-cherry aphid, the corn leaf aphid, and the English grain aphid. The presence of the disease in wheat is diagnosed by the presence of aphid vectors, the occurrence of yellowed leaves, and stunted plants grouped in small patches among normal plants, although visual diagnosing is complicated because it can be confused with wheat streak mosaic, nutrient deficiency, root diseases or environmental stress. By observing the data we clearly see that the frequency of the English grain aphid increases from the west to the east of Kansas, closely related with higher precipitations and more area planted with wheat towards the east.<br />
I fitted three different GAM models considering different distributions: negative binomial, poisson, and zero inflated poisson. I modeled the abundance (count) as a function of the percentage of grassland within a 5 km radius, the year, and a smooth (random) term including latitude and longitude.</p>
</div>
<div id="april-16" class="section level2 hasAnchor" number="6.16">
<h2><span class="header-section-number">6.16</span> April 16<a href="math-model-review.html#april-16" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Today in class we kept exploring the disease data related to the abundance of the Bird Cherry-oat Aphid, and the proportion infected with barley yellow dwarf virus (BYDV). In addition, we had a look at an Earthquake data from Kansas that recorded earthquake events between 1977 and 2020. We explored the data and saw an apparent increase in earthquakes over time with a really high frequency between 2014-2020, although it seems something weird is going on between 1990 and 2012, possibly indicating missing data or earthquake events not accounted for during that time.</p>
</div>
<div id="april-18" class="section level2 hasAnchor" number="6.17">
<h2><span class="header-section-number">6.17</span> April 18<a href="math-model-review.html#april-18" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Last Thursday in class, I kept working on Activity 3. I run four GAM models with different distributions: poisson, negative binomial, zero inflated poisson, and gaussian distribution. I split the data into training (60%) and testing (40%). According to the Akaike Information Criteria, the best two models are the negative binomial and the gaussian. While the models with the lower mean absolute error were the negative binomial and the zero inflated poisson (22 and 24).</p>
</div>
<div id="april-23" class="section level2 hasAnchor" number="6.18">
<h2><span class="header-section-number">6.18</span> April 23<a href="math-model-review.html#april-23" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Today in class we kept working on the earthquake data set, and discussed the dynamism of the data because it can be modified over time based on new or dropped earthquakes events. We visualized the data on space (removing time) with the map, and we saw more frequency in the south center, we also visualize the time trend (removed space) and saw way more frequency in recent years. Also, we saw an animation of the earthquakes over time visualizing a higher frequency over the last 10 years in the south center region.<br />
</p>
<p>Goals of the study: prediction and inference of the events, where is the area with highest probability of an earthquake? we don’t want to predict the probability at a point because it will probably be zero.<br />
Data model: <span class="math inline">\(y=z\)</span><br />
Process model: <span class="math inline">\(z \sim IPPP(\lambda(s,e))\)</span><br />
<span class="math inline">\(\lambda(s,t)=e^{\beta_0+\beta1 \cdot x(s,t)+\eta_s+\eta_t}\)</span><br />
<span class="math inline">\(\eta_s \sim MVN(0,\sum_s)\)</span><br />
<span class="math inline">\(\eta_t \sim MVN(0,\sum_t)\)</span><br />
</p>
<p>We modeled the earthquake data and saw that the expected number of earthquakes per 100 km<span class="math inline">\(^2\)</span> per year is higher when we are close to an oil well.</p>
</div>
<div id="april-30" class="section level2 hasAnchor" number="6.19">
<h2><span class="header-section-number">6.19</span> April 30<a href="math-model-review.html#april-30" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Something I learned today is that using GAMs to predict values outside the observed range of your data (forecast or hindcast) is not advisable due to the significantly increased uncertainty. When making predictions beyond this range, it’s important to clearly indicate the heightened level of uncertainty associated with these estimates.<br />
<br />
Today is the last class and we also reviewed all the deadlines for the peer-review project, final project, presentations, and final portfolio.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="axis-labels-name-correctly-for-showing-a-histogram-is-a-pdf-is-not-a-count-is-density-in-histfreq-f..html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/Journal_STAT764.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
